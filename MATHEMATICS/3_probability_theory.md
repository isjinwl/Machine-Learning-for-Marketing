>**Neural Network and Deep Learning(邱锡鹏，2020)**[[Book]](https://nndl.github.io/)<br/>
> #### Appendix.D 概率论
> + 样本空间：一个随机试验所有可能结果的集合.随机试验中的每个可能结果称为*样本点*.
> + 随机事件/事件：一个被赋予*概率*的事物集合，或者说是样本空间中的一个子集.
> + 概率(Probability)：表示一个*随机事件*发生的可能性大小，为0到1之间的实数.
> + 随机变量：用一个数X表示随机试验的结果，X的取值随试验结果的不同而变化，是样本点的一个函数.
>    + 离散随机变量：随机变量X有N个*有限可列举*的取值<!-- $\lbrace x_1,...,x_N \rbrace$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Clbrace%20x_1%2C...%2Cx_N%20%5Crbrace">.
>       + 离散随机变量的概率分布：<!-- $p(X_n)=P(X=x_n), \sum_{n=1}^N p(x_n)=1, p(x_n) \ge 0, \forall n \in \lbrace 1,...,N \rbrace.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p(X_n)%3DP(X%3Dx_n)%2C%20%5Csum_%7Bn%3D1%7D%5EN%20p(x_n)%3D1%2C%20p(x_n)%20%5Cge%200%2C%20%5Cforall%20n%20%5Cin%20%5Clbrace%201%2C...%2CN%20%5Crbrace."> 常见离散随机变量的概率分布：
>         + 伯努利分布(Bernoulli Distribution)：<!-- $p(x)=\mu^x(1-\mu)^{(1-x)}.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p(x)%3D%5Cmu%5Ex(1-%5Cmu)%5E%7B(1-x)%7D."><br/>x取值0或1(事件A不发生或发生)，μ(或1-μ)：一次试验中事件A发生(或不发生)的平均概率.
>         + 二项分布(Binomial Distribution)：<!-- $p(X=k)=\begin{pmatrix}N\\k\end{pmatrix}\mu^k(1-\mu)^{(N-k)},k=0,\cdots,N.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p(X%3Dk)%3D%5Cbegin%7Bpmatrix%7DN%5C%5Ck%5Cend%7Bpmatrix%7D%5Cmu%5Ek(1-%5Cmu)%5E%7B(N-k)%7D%2Ck%3D0%2C%5Ccdots%2CN."><br/>在N次伯努利试验中发生k次事件A的概率.<!-- $\begin{pmatrix}N\\k\end{pmatrix}$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Cbegin%7Bpmatrix%7DN%5C%5Ck%5Cend%7Bpmatrix%7D">表示组合总数.<br/>
>         \* 排列组合：<br/>
>         (1) *排列*(Permutation|Arrangement)是指从*给定个数*的元素中取出*指定个数*的元素进行*排序*，N个不同元素可以有N！种不同的*排列方式*，即*N的阶乘*：<!-- $N!\triangleq N \times (N-1) \times \cdots \times 3 \times 2 \times 1.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=N!%5Ctriangleq%20N%20%5Ctimes%20(N-1)%20%5Ctimes%20%5Ccdots%20%5Ctimes%203%20%5Ctimes%202%20%5Ctimes%201."><br/>如果从*N个元素*中取出*k个元素*，这k个元素的排列总数为<!-- $p_N^k \triangleq N \times (N-1) \times \cdots \times (N-k+1) = \frac{N!}{(N-k)!}.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p_N%5Ek%20%5Ctriangleq%20N%20%5Ctimes%20(N-1)%20%5Ctimes%20%5Ccdots%20%5Ctimes%20(N-k%2B1)%20%3D%20%5Cfrac%7BN!%7D%7B(N-k)!%7D."><br/>(2)*组合*(Combination)与*排列*的区别在于*组合*不考虑排序，只考虑从N个元素中取出k个元素可能存在的*组合数*，因此除去k个元素可以有的k！个排列方式：<!-- $C_N^k \triangleq {k \choose N}=\frac{p_N^k}{k!}=\frac{N!}{(N-k)!k!}=\frac{N \times (N-1) \times \cdots \times (N-k+1)}{k \times (k-1) \times \cdots \times 1}.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=C_N%5Ek%20%5Ctriangleq%20%7Bk%20%5Cchoose%20N%7D%3D%5Cfrac%7Bp_N%5Ek%7D%7Bk!%7D%3D%5Cfrac%7BN!%7D%7B(N-k)!k!%7D%3D%5Cfrac%7BN%20%5Ctimes%20(N-1)%20%5Ctimes%20%5Ccdots%20%5Ctimes%20(N-k%2B1)%7D%7Bk%20%5Ctimes%20(k-1)%20%5Ctimes%20%5Ccdots%20%5Ctimes%201%7D."><br/><!-- $C_N^k = C_N^{N-k}$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=C_N%5Ek%20%3D%20C_N%5E%7BN-k%7D"><br/><!-- $C_N^{k-1}+C_N^k=C_{N+1}^k$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=C_N%5E%7Bk-1%7D%2BC_N%5Ek%3DC_%7BN%2B1%7D%5Ek"><br/><!-- $C_N^0+C_N^1+ \cdots +C_N^N=2^N$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=C_N%5E0%2BC_N%5E1%2B%20%5Ccdots%20%2BC_N%5EN%3D2%5EN"><br/><!-- $C_k^k+C_{k+1}^k+ \cdots +C_N^k=C_{N+1}^{k+1}$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=C_k%5Ek%2BC_%7Bk%2B1%7D%5Ek%2B%20%5Ccdots%20%2BC_N%5Ek%3DC_%7BN%2B1%7D%5E%7Bk%2B1%7D"><br/><!-- $\sum_{i=0}^k C_n^i C_m^{k-i}=C_{n+m}^k$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Csum_%7Bi%3D0%7D%5Ek%20C_n%5Ei%20C_m%5E%7Bk-i%7D%3DC_%7Bn%2Bm%7D%5Ek">
>    + 连续随机变量：随机变量X的取值*不可列举*，由全部实数或一部分区间构成，<!-- $X=\lbrace x|a \le x \le b \rbrace, -\infty \le a \le b \le \infty.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=X%3D%5Clbrace%20x%7Ca%20%5Cle%20x%20%5Cle%20b%20%5Crbrace%2C%20-%5Cinfty%20%5Cle%20a%20%5Cle%20b%20%5Cle%20%5Cinfty."> 与离散随机变量不同的是，连续随机变量X取一个具体值<!-- $x_i$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=x_i">的概率为0.
>       + 概率密度函数(Probability Density Function.PDF)：<br/>连续随机变量的概率分布，p(x)为可积函数(可微 <!-- $\Rightarrow$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5CRightarrow">可积)，<br/><!-- ${\int_{-\infty}^{+\infty}p(x)dx}=1, p(x) \ge 0.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%7B%5Cint_%7B-%5Cinfty%7D%5E%7B%2B%5Cinfty%7Dp(x)dx%7D%3D1%2C%20p(x)%20%5Cge%200."><br/>给定概率密度函数p(x)，便可以计算出随机变量落入某一区域的概率. <!-- $\mathcal{R}$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Cmathcal%7BR%7D">表示x的非常小的邻域，<!-- $|\mathcal{R}|$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%7C%5Cmathcal%7BR%7D%7C">表示<!-- $\mathcal{R}$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Cmathcal%7BR%7D">的大小，则<!-- $p(x)|\mathcal{R}|$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p(x)%7C%5Cmathcal%7BR%7D%7C">可以反映随机变量X处于区域<!-- $\mathcal{R}$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Cmathcal%7BR%7D">的概率大小. 常见连续随机变量概率分布：
>       + 均匀分布(Uniform Distribution)：<br/><!-- $p(x)=\begin{cases}\frac{1}{b-a}&,a\le x \le b\\0 & ,x<a \text{ or } x>b\end{cases}$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p(x)%3D%5Cbegin%7Bcases%7D%5Cfrac%7B1%7D%7Bb-a%7D%26%2Ca%5Cle%20x%20%5Cle%20b%5C%5C0%20%26%20%2Cx%3Ca%20%5Ctext%7B%20or%20%7D%20x%3Eb%5Cend%7Bcases%7D">
>       + 正态分布(Normal Distribution|Gaussian Distribution)：<br/><!-- $X \backsim \mathcal{N}(\mu,\sigma^2),p(x)=\frac{1}{\sqrt{2 \pi \sigma}}e^{-\frac{(x-\mu)^2}{2 \sigma^2}},\mu,\sigma \in C,(\sigma > 0).$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=X%20%5Cbacksim%20%5Cmathcal%7BN%7D(%5Cmu%2C%5Csigma%5E2)%2Cp(x)%3D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%20%5Cpi%20%5Csigma%7D%7De%5E%7B-%5Cfrac%7B(x-%5Cmu)%5E2%7D%7B2%20%5Csigma%5E2%7D%7D%2C%5Cmu%2C%5Csigma%20%5Cin%20C%2C(%5Csigma%20%3E%200)."><br/>Standard Normal Distribution: <!-- $X \backsim \mathcal{N}(0,1)$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=X%20%5Cbacksim%20%5Cmathcal%7BN%7D(0%2C1)">
>    + 累计分布函数(Cumulative Distribution Function, CDF): 随机变量X的取值≤x的概率.<br/><!-- $cdf(x)=p(X\le x)=\int_{-\infty}^x p(t)dt.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=cdf(x)%3Dp(X%5Cle%20x)%3D%5Cint_%7B-%5Cinfty%7D%5Ex%20p(t)dt.">
> + 随机向量：一组*随机变量*构成的向量:K维*随机向量*<!-- $X=[X_1,X_2,\cdots,X_K]$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=X%3D%5BX_1%2CX_2%2C%5Ccdots%2CX_K%5D">，一维随机向量即随机变量.
>   + 离散随机向量-联合概率分布(Joint Probability Distribution)：<br/><!-- $P(X_1=x_1,X_2=x_2,\cdots,X_K=x_K)=p(x_1,x_2,\cdots,x_K)\ge 0,\forall x_1 \in \Omega_1,x_2 \in \Omega_2,\cdots,x_K \in \Omega_K.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=P(X_1%3Dx_1%2CX_2%3Dx_2%2C%5Ccdots%2CX_K%3Dx_K)%3Dp(x_1%2Cx_2%2C%5Ccdots%2Cx_K)%5Cge%200%2C%5Cforall%20x_1%20%5Cin%20%5COmega_1%2Cx_2%20%5Cin%20%5COmega_2%2C%5Ccdots%2Cx_K%20%5Cin%20%5COmega_K."><br/><!-- $\sum_{x_1 \in \Omega_1,x_2 \in \Omega_2,\cdots,x_K \in \Omega_K}p(x_1,x_2,\cdots,x_K)=\sum_{x_1 \in \Omega_1}\sum_{x_2 \in \Omega_2} \cdots \sum_{x_K \in \Omega_K}p(x_1,x_2,\cdots,x_K)=1.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Csum_%7Bx_1%20%5Cin%20%5COmega_1%2Cx_2%20%5Cin%20%5COmega_2%2C%5Ccdots%2Cx_K%20%5Cin%20%5COmega_K%7Dp(x_1%2Cx_2%2C%5Ccdots%2Cx_K)%3D%5Csum_%7Bx_1%20%5Cin%20%5COmega_1%7D%5Csum_%7Bx_2%20%5Cin%20%5COmega_2%7D%20%5Ccdots%20%5Csum_%7Bx_K%20%5Cin%20%5COmega_K%7Dp(x_1%2Cx_2%2C%5Ccdots%2Cx_K)%3D1.">
>      + 多项分布(Multinomial Distribution)：e.g.,An urn contains 8 red balls, 3 yellow balls and 9 white balls. 6 balls are randomly selected with/without replacement. What is the probability 2 are red, 1 is yellow, and 3 are white?<br/>(With Replacement)<!-- $P(X_1=x_1,X_2=x_2,\cdots,X_K=x_K)=\frac{n!}{x_1!x_2!\cdots x_K!}p_1^{x_1}p_2^{x_2}\cdots p_K^{x_K},n:the number of balls; K:the number of colors.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=P(X_1%3Dx_1%2CX_2%3Dx_2%2C%5Ccdots%2CX_K%3Dx_K)%3D%5Cfrac%7Bn!%7D%7Bx_1!x_2!%5Ccdots%20x_K!%7Dp_1%5E%7Bx_1%7Dp_2%5E%7Bx_2%7D%5Ccdots%20p_K%5E%7Bx_K%7D%2Cn%3Athe%20number%20of%20balls%3B%20K%3Athe%20number%20of%20colors."><br/><!-- $p(X_1=2,X_1=1,X_3=3)=\frac{6!}{2!1!3!}(\frac{8}{20})^2(\frac{3}{20})^1(\frac{9}{20})^3$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p(X_1%3D2%2CX_1%3D1%2CX_3%3D3)%3D%5Cfrac%7B6!%7D%7B2!1!3!%7D(%5Cfrac%7B8%7D%7B20%7D)%5E2(%5Cfrac%7B3%7D%7B20%7D)%5E1(%5Cfrac%7B9%7D%7B20%7D)%5E3"><br/>(Without Replacement)<!-- $P(X_1=x_1,X_2=x_2,\cdots,X_K=x_K)=\frac{\left(\frac{2}{8}\right)\left(\frac{1}{3}\right)\left(\frac{3}{9}\right)}{\left(\frac{6}{20}\right)}.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=P(X_1%3Dx_1%2CX_2%3Dx_2%2C%5Ccdots%2CX_K%3Dx_K)%3D%5Cfrac%7B%5Cleft(%5Cfrac%7B2%7D%7B8%7D%5Cright)%5Cleft(%5Cfrac%7B1%7D%7B3%7D%5Cright)%5Cleft(%5Cfrac%7B3%7D%7B9%7D%5Cright)%7D%7B%5Cleft(%5Cfrac%7B6%7D%7B20%7D%5Cright)%7D.">
>   + 连续随机向量-联合概率密度函数(Joint Probability Density Function)：一个K维连续随机变量X的联合概率分布满足:<br/><!-- $p(x)=p(x_1,x_2,\cdots,x_K) \ge 0$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p(x)%3Dp(x_1%2Cx_2%2C%5Ccdots%2Cx_K)%20%5Cge%200"><br/><!-- $\int_{-\infty}^{\infty}\cdots\int_{-\infty}^{\infty}p(x_1,\cdots,x_K)d_1 \cdots d_K=1$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Cint_%7B-%5Cinfty%7D%5E%7B%5Cinfty%7D%5Ccdots%5Cint_%7B-%5Cinfty%7D%5E%7B%5Cinfty%7Dp(x_1%2C%5Ccdots%2Cx_K)d_1%20%5Ccdots%20d_K%3D1">
>      + 多元正态/高斯分布(Multivariate Normal|Gaussian Distribution)：<!-- $p(x)=\frac{1}{(2 \pi)^{\frac K2}|\Sigma|^{\frac 12}}e^{-\frac 12 \begin{bmatrix}X-\mu\end{bmatrix}^T \Sigma^{-1}\begin{bmatrix}X-\mu\end{bmatrix}},-\infty<x_k<\infty.$ --> <img style="transform: translateY(0.1em); background: white;" src="..\svg\W3K1nXOaBI.svg"><br/>e.g.,Let <!-- $X_1,X_2$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=X_1%2CX_2"> are independent with pdf <!-- $\mathcal{N}(\mu_1,\sigma_1^2),\mathcal{N}(\mu_2,\sigma_2^2)$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Cmathcal%7BN%7D(%5Cmu_1%2C%5Csigma_1%5E2)%2C%5Cmathcal%7BN%7D(%5Cmu_2%2C%5Csigma_2%5E2)">.That means <!-- $\sigma_{12}=0,\rho=0,f(x_1,x_2)=f(x_1)f(x_2)$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Csigma_%7B12%7D%3D0%2C%5Crho%3D0%2Cf(x_1%2Cx_2)%3Df(x_1)f(x_2)">.<br/><!-- $X=[x_1,x_2]^T,\mu=[\mu_1,\mu_2]^T,\Sigma=\begin{bmatrix}\sigma_{11}&\sigma_{12}\\\sigma_{21}&\sigma_{22}\end{bmatrix}=\begin{bmatrix}\sigma_1^2&\sigma_{12}\\\sigma_{21}&\sigma_2^2\end{bmatrix}=\begin{bmatrix}\sigma_1^2&0\\0&\sigma_2^2\end{bmatrix}$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=X%3D%5Bx_1%2Cx_2%5D%5ET%2C%5Cmu%3D%5B%5Cmu_1%2C%5Cmu_2%5D%5ET%2C%5CSigma%3D%5Cbegin%7Bbmatrix%7D%5Csigma_%7B11%7D%26%5Csigma_%7B12%7D%5C%5C%5Csigma_%7B21%7D%26%5Csigma_%7B22%7D%5Cend%7Bbmatrix%7D%3D%5Cbegin%7Bbmatrix%7D%5Csigma_1%5E2%26%5Csigma_%7B12%7D%5C%5C%5Csigma_%7B21%7D%26%5Csigma_2%5E2%5Cend%7Bbmatrix%7D%3D%5Cbegin%7Bbmatrix%7D%5Csigma_1%5E2%260%5C%5C0%26%5Csigma_2%5E2%5Cend%7Bbmatrix%7D"><br/><!-- $\sigma_{12}=\sigma_{21}=\rho\sigma_1\sigma_2$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Csigma_%7B12%7D%3D%5Csigma_%7B21%7D%3D%5Crho%5Csigma_1%5Csigma_2"><br/><!-- $p(x_1,x_2)=p(x_1)p(x_2)={\frac{1}{\sqrt{2 \pi \sigma_1}}e^{-\frac{(x_1-\mu)^2}{2 \sigma_1^2}}}{\frac{1}{\sqrt{2 \pi \sigma_2}}e^{-\frac{(x_2-\mu)^2}{2 \sigma_2^2}}}=\frac{1}{(2 \pi)^{\frac 22}(\sigma_1^2 \sigma_2^2)^{\frac 12}}e^{-\frac 12[(\frac{x_1-\mu_1}{\sigma_1})^2+(\frac{x_2-\mu_2}{\sigma_2})^2]}$ --> <img style="transform: translateY(0.1em); background: white;" src="..\svg\4IdLwZJFNi.svg"><br/><!-- $|\Sigma|=\sigma_1^2\sigma_2^2-\sigma_{12}^2=\sigma_1^2\sigma_2^2,\to constant=\frac{1}{(2 \pi)^{\frac 22}(\sigma_1^2 \sigma_2^2)^{\frac 12}}=\frac{1}{(2 \pi)^{\frac 22}|\Sigma|^{\frac 12}}$ --> <img style="transform: translateY(0.1em); background: white;" src="..\svg\gJqUlYASKY.svg"><br/><!-- $-\frac 12[(\frac{x_1-\mu_1}{\sigma_1})^2+(\frac{x_2-\mu_2}{\sigma_2})^2]=-\frac 12 \begin{bmatrix}x_1-\mu_1&x_2-\mu_2\end{bmatrix} \begin{bmatrix}\sigma_1^2&0\\0&\sigma_2^2\end{bmatrix}^{-1} \begin{bmatrix}x_1-\mu_1\\x_2-\mu_2\end{bmatrix}$ --> <img style="transform: translateY(0.1em); background: white;" src="..\svg\Drw1qkD33H.svg"><br/><!-- $=-\frac 12 \begin{bmatrix}x_1-\mu_1&x_2-\mu_2\end{bmatrix} \frac{1}{\sigma_1^2 \sigma_2^2}\begin{bmatrix}\sigma_2^2&0\\0&\sigma_1^2\end{bmatrix} \begin{bmatrix}x_1-\mu_1\\x_2-\mu_2\end{bmatrix}$ --> <img style="transform: translateY(0.1em); background: white;" src="..\svg\e0jBSyVmht.svg"><br/><!-- $=-\frac 12 \begin{bmatrix}X-\mu\end{bmatrix}^T \Sigma^{-1}\begin{bmatrix}X-\mu\end{bmatrix}.$ --> <img style="transform: translateY(0.1em); background: white;" src="..\svg\8DK5QHNuNH.svg"><br/><!-- $\therefore p(x_1,x_2)=\frac{1}{(2 \pi)^{\frac 22}|\Sigma|^{\frac 12}}e^{-\frac 12 \begin{bmatrix}X-\mu\end{bmatrix}^T \Sigma^{-1}\begin{bmatrix}X-\mu\end{bmatrix}}$ --> <img style="transform: translateY(0.1em); background: white;" src="..\svg\cSRfVPtDJU.svg">.<br/>
\*Multivariate normal distribution(J Maiti, 2014)[[Video]](https://www.youtube.com/watch?v=YgExEVji7xs)<br/>\*The Multivariate Gaussian Distribution(Chuong B. Do, 2008)[[PDF]](http://cs229.stanford.edu/section/gaussians.pdf)<br/>
>      + 各项同性高斯分布(Isotropic Gaussian Distribution)：
>      + 狄利克雷分布()：
> + 边际分布(Marginal Distribution)：
>    + e.g.,二维离散随机向量：<br/><!-- $p(x,y)\ge 0,\sum_{x \in \Omega_x}\sum_{y \in \Omega_y}p(x,y)=1:\sum_{x \in \Omega_x}p(x,y)=p(y),\sum_{y \in \Omega_y}p(x,y)=p(x).$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p(x%2Cy)%5Cge%200%2C%5Csum_%7Bx%20%5Cin%20%5COmega_x%7D%5Csum_%7By%20%5Cin%20%5COmega_y%7Dp(x%2Cy)%3D1%3A%5Csum_%7Bx%20%5Cin%20%5COmega_x%7Dp(x%2Cy)%3Dp(y)%2C%5Csum_%7By%20%5Cin%20%5COmega_y%7Dp(x%2Cy)%3Dp(x).">
>    + e.g.,二维连续随机向量:<br/><!-- $p(x)=\int_{-\infty}^{\infty}p(x,y)dy,p(y)=\int_{-\infty}^{\infty}p(x,y)dx.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p(x)%3D%5Cint_%7B-%5Cinfty%7D%5E%7B%5Cinfty%7Dp(x%2Cy)dy%2Cp(y)%3D%5Cint_%7B-%5Cinfty%7D%5E%7B%5Cinfty%7Dp(x%2Cy)dx.">
> + 条件概率分布：<!-- $p(y|x)=\frac{p(x,y)}{p(x)}.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p(y%7Cx)%3D%5Cfrac%7Bp(x%2Cy)%7D%7Bp(x)%7D.">
> + 贝叶斯定理：<!-- $\begin{cases}p(y|x)=\frac{p(x,y)}{p(x)}\\p(x|y)=\frac{p(x,y)}{p(y)}\end{cases}\Rightarrow p(y|x)=\frac{p(y)p(x|y)}{p(x)}.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Cbegin%7Bcases%7Dp(y%7Cx)%3D%5Cfrac%7Bp(x%2Cy)%7D%7Bp(x)%7D%5C%5Cp(x%7Cy)%3D%5Cfrac%7Bp(x%2Cy)%7D%7Bp(y)%7D%5Cend%7Bcases%7D%5CRightarrow%20p(y%7Cx)%3D%5Cfrac%7Bp(y)p(x%7Cy)%7D%7Bp(x)%7D.">
> + 独立与条件独立：
>    + 独立: <!-- $p(x,y)=p(x)p(y)\Leftrightarrow X \bot Y.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p(x%2Cy)%3Dp(x)p(y)%5CLeftrightarrow%20X%20%5Cbot%20Y.">
>    + 条件独立: <!-- $p(x,y|z)=p(x|z)p(y|z)\Leftrightarrow X \bot Y|Z.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=p(x%2Cy%7Cz)%3Dp(x%7Cz)p(y%7Cz)%5CLeftrightarrow%20X%20%5Cbot%20Y%7CZ.">
> + 期望与方差：
>    + 期望(Expectation):<!-- $E[X]=E[X-E(X)]^2.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=E%5BX%5D%3DE%5BX-E(X)%5D%5E2."><br/>离散型随机变量：<!-- $E(X)=\sum_{n=1}^N x_n p(x_n).$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=E(X)%3D%5Csum_%7Bn%3D1%7D%5EN%20x_n%20p(x_n)."><br/>连续型随机变量：<!-- $E(X)=\int_{\mathbb{R}}xp(x)dx.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=E(X)%3D%5Cint_%7B%5Cmathbb%7BR%7D%7Dxp(x)dx.">
>    + 方差(Variance):用来定义随机变量X的概率分布的离散程度.<br/><!-- $var(X)=E[(X-\mu)^2]=E[(X-E(X))^2]=E[X^2]-E[X]^2.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=var(X)%3DE%5B(X-%5Cmu)%5E2%5D%3DE%5B(X-E(X))%5E2%5D%3DE%5BX%5E2%5D-E%5BX%5D%5E2."><br/>离散型随机变量：<!-- $var(X)=\sum_{n=1}^N p(x_n)(x_n-\mu)^2.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=var(X)%3D%5Csum_%7Bn%3D1%7D%5EN%20p(x_n)(x_n-%5Cmu)%5E2."><br/>连续型随机变量：<!-- $var(X)=\int_{\mathbb{R}}(x-\mu)^2 f(x)dx.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=var(X)%3D%5Cint_%7B%5Cmathbb%7BR%7D%7D(x-%5Cmu)%5E2%20f(x)dx.">
>    + 协方差(Covariance):衡量两个随机变量的分布之间的总体变化性，或两个随机变量之间的线性相关性，协方差为0则称两个随机变量线性不相关(两个随机变量的分布之间的总体变化性在线性关系上不相关，可能存在某种非线性的函数关系.这里的线性相关和线性代数中的定义不同.)<br/><!-- $cov(X,Y)=E[(X-E[X])(Y-E(Y))^T].$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=cov(X%2CY)%3DE%5B(X-E%5BX%5D)(Y-E(Y))%5ET%5D.">
>       + 相关系数: <!-- $\rho=\frac{cov(X,Y)}{\sigma_X \sigma_Y}.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5Crho%3D%5Cfrac%7Bcov(X%2CY)%7D%7B%5Csigma_X%20%5Csigma_Y%7D."><br/>相关系数可以看作剔除了两个随机变量量纲、标准化后的特殊协方差，它消除了两个变量变化幅度的影响，单纯反映两个变量每单位变化的相似程度，且同向变化则为正，反之为负.
>       + 协方差矩阵(Covariance Matrix):
>         + 协方差矩阵cov(X,Y)的第(m,n)个元素是随机变量<!-- $X_m,Y_n$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=X_m%2CY_n">的协方差.
>         + 两个随机向量之间的协方差矩阵为*对角矩阵*，则称两个随机向量是无关的.
>         + 单个随机向量X的协方差矩阵为<!-- $\Sigma=cov(X)=cov(X,X)=E[(X-E[X])(X-E(X))^T]=E[XX^T]-\mu\mu^T.$ --> <img style="transform: translateY(0.1em); background: white;" src="https://render.githubusercontent.com/render/math?math=%5CSigma%3Dcov(X)%3Dcov(X%2CX)%3DE%5B(X-E%5BX%5D)(X-E(X))%5ET%5D%3DE%5BXX%5ET%5D-%5Cmu%5Cmu%5ET.">
>    + Jensen不等式(Jensen's Inequality):
>    + 大数定律(Law of Large Numbers):
> + 随机过程(Stochastic Process)：
>    + 马尔可夫过程(Markov Process)：
>       + 马尔可夫性质：在随机过程中，马尔可夫性质是指一个随机过程在给定现在及所有历史状态的情况下，其未来状态的条件概率分布仅依赖于当前状态.也可以描述为给定当前状态，将来状态和历史状态是条件独立的.<br/>$P(X_{t+1}=x_{t+1}|X_{0:t}=x_{0:t})=P(X_{t+1}=x_{t+1}|X_t=x_t).$
>       + 马尔可夫链(Markov Chain)：离散时间的马尔可夫过程
>    + 高斯过程：
>----